---
title: "Proyecto_optimizacion"
author: "Grupo optimización"
date: "`r Sys.Date()`"
output: html_document
---

# Proyecto grupal CA-0305

## Preparación

Para medir los tiempos de ejecución se utilizará la librería [microbenchmark](https://cran.r-project.org/web/packages/microbenchmark/microbenchmark.pdf), la cual permite medir el tiempo de una función múltiples veces.

Así, primeramente se leen varios scripts que contienen diferentes funciones y clases que se usarán a lo largo del proyecto.

```{r scripts_preparacion}
# Scripts de R para la preparación
scripts_r <- c(
  "cod/r/librerias.R",
  "cod/r/fun_calcular_tiempos.R",
  "cod/r/fun_df_tiempos_simples.R",
  "cod/r/fun_df_prod_acum.R",
  "cod/r/fun_df_texto.R",
  "cod/r/fun_df_tiempos_dobles.R",
  "cod/r/fun_df_tiempos_graficos.R",
  "cod/r/fun_df_tiempos_elimcol.R",
  "cod/r/fun_df_tiempos_imputacion.R",
  "cod/r/fun_lectura_excel.R",
  "cod/r/fun_lectura_txt.R",
  "cod/r/fun_lectura_csv.R",
  "cod/r/fun_graficos_simples.R",
  "cod/r/grafico_doble_prodacum.R",
  "cod/r/grafico_doble_graficos.R",
  "cod/r/grafico_doble_texto.R",
  "cod/r/fun_graficos_dobles_limpieza.R",
  "cod/r/fun_graficos_dobles_elimcols.R",
  "cod/r/fun_graficos_dobles_agrupacion.R"
)

# Se leen los scripts
invisible(lapply(scripts_r, source))

# Scripts de Python para la preparación
scripts_python <- c(
  "cod/python/librerias.py",
  "cod/python/clases.py"
)

# Se leen los scripts
invisible(lapply(scripts_python, source_python))
```

## Operaciones simples

Primeramente, se crea un objeto de la clase OperacionesBasicas y de GenerarDataframes que se usará a lo largo de esta sección.

```{python objeto_operaciones_basicas}
obj_operaciones_basicas = OperacionesBasicas('data/El_principito.txt', np.random.uniform(0, 2, 100_000).tolist(),'data/El_principito.txt' )
```

```{python obj_generar_df}
obj_generadordf = GenerarDataframes(['Alejandro', 'Eyeri', 'Santiago', 'Paula'])
```

### Operaciones matriciales

Inicialmente se intentaron usar librerías como Matrix, bigmemory, LAPLACK, BLAS, bigalgebra o expm, pero algunas de estas requieren de una instalación externa y más compleja que una librería común y corriente, además de que dichas librerías no optimizan la multiplicación elemento a elemento sino que optimizan el calculo matricial de matrices, o se especializan en otros tipos de procedimientos con matrices, lo cual no es lo que se quiere en este ejercicio.

Esto quiere decir que, por ejemplo, al hacer A %\^% 2 o, lo que es lo mismo, A %\*% A, se hace la multiplicación matricial de A con A y no la multiplicación elemento a elemento de A con A, que es lo deseado. También se intentó paralelizar el código usando las librerías doParallel y foreach, pero resultó ser bastante más ineficiente hacer esto que hacerlo por defecto.

Así, se decidió que la mejor manera de hacer este ejercicio es hacerlo con lo que trae R por defecto; es decir, crear una matriz con matrix() y utilizar el operador \^ para elevar a la 100 elemento a elemento, así como \* y + para multiplicarla por 10 y sumarle 5, respectivamente.

Si bien el tiempo de ejecución puede parecer alto, es lo mejor que se pudo encontrar que está a nuestro alcance.

Así, se leen los scripts necesarios para este ejercicio.

```{r scripts_matrices}
# Scripts para las operaciones matriciales
scripts <- c(
  "cod/r/fun_creacion_matriz.R",
  "cod/r/fun_operacion_matricial.R",
  "cod/r/creacion_matriz.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se calculan los tiempos de ejecución del ejercicio.

```{r tiempos_operacion_matricial_r}
calcular.tiempos(function()
  operacion.matricial(matriz))
```

Se guardan los tiempos promedio por integrante de realizar la operación matricial.

```{r tiempos_matrices_r}
# Se guarda este tiempo por integrante en un dataframe
tiempos.matrices <- df.tiempos.simples(c(4.246259, 5.99183, 7.257987, 7.87946))
```

Se grafica lo anterior.

```{r graf_tiempos_matrices_r}
graficos.simples(tiempos.matrices, "coral3", "Tiempos del ejercicio de matrices")
```

Se procede a hacer lo mismo en Python.

```{python tiempos_operacion_matricial_py}
obj_operaciones_basicas.medir_tiempo("operacion_matricial()")
```

```{python tiempos_matriz_numba}
obj_operaciones_basicas.medir_tiempo("operacion_matricial_numba()")
```

```{python tiempos_matrices_py}
df_operacion_matriz_py = obj_generadordf.tiempos_dobles('Tiempos numexpr', [2.38700, 0.61500, 0.34238, 2.34700 ], 'Tiempos numba', [0.73300, 0.22180, 0.24621, 0.46500 ])
```

```{python graf_tiempos_matrices_py}
GenerarGraficos(df_operacion_matriz_py).barras_agrupadas('integrante', 'Tiempos numexpr', 'Tiempos numba', ['Condición', 'Numexpr', 'Numba'], 'Tiempos del ejercicio de matricesl')
```

### Producto acumulado

Scripts necesarios para el ejercicio.

```{r scripts_prod_acum}
# Scripts para el producto acumulado
scripts <- c(
  "cod/r/fun_producto_acumulado_cumprod.R",
  "cod/r/fun_producto_acumulado_sapply.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se calculan los tiempos de ejecución del ejercicio tanto con cumprod como con sapply.

```{r tiempo_cumprod}
calcular.tiempos(function()
  prod.acum.cumprod(runif(
    100000, min = .Machine$double.eps, max = 2
  )))
```

```{r tiempo_sapply}
calcular.tiempos(function()
  prod.acum.sapply(runif(
    100000, min = .Machine$double.eps, max = 2
  )))
```

Se guardan los tiempos promedio por integrante de realizar el producto acumulado tanto con cumprod como con sapply.

```{r tiempos_producto_acumulado}
tiempos.prod.acum.acumprod <- df.tiempos.simples(c(0.001, 0.01, 0.006, 0.02))

tiempos.prod.acum.sapply <- df.tiempos.simples(c(27.93, 44.54, 27.82, 115.22))
```

Se grafica lo anterior en 2 gráficos por separado, ya que en un solo gráfico no se podría apreciar el tiempo promedio de ejecución usando cumprod, pues este es muy bajo en comparación con el tiempo promedio usando sapply.

```{r grafico_producto_acumulado}
graficos.simples(
  tiempos.prod.acum.acumprod,
  "darkmagenta",
  "Tiempos del producto acumulado con acumprod"
)

graficos.simples(tiempos.prod.acum.sapply,
                 "darkcyan",
                 "Tiempos del producto acumulado con sapply")
```

### Cifrado César

Scripts necesarios para el ejercicio.

```{r scripts_cifrado_cesar}
# Scripts para el cifrado César
scripts <- c(
  "cod/r/descarga_el_principito.R",
  "cod/r/cifrado_cesar_chartr.R",
  "cod/r/cifrado_cesar_stringi.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se calculan los tiempos de ejecución del ejercicio tanto con chartr como con stringi.

```{r tiempos_chartr}
calcular.tiempos(function()
  cifrado.chartr(principito, 5))
```

```{r tiempos_stingri}
calcular.tiempos(function()
  cifrado.stringi(principito, 5))
```

Se guardan los tiempos promedio por integrante de realizar el Cifrado César

```{r tiempos_cifrado_texto}
tiempos.texto <- df.tiempos.texto(
  c(0.012, 0.02, 0.016, 0.044),
  c(1.25, 2.46	, 1.3, 3.44),
  c("Santiago", "Paula", "Eyeri", "Alejandro")
)
```

Se grafica lo anterior.

```{r grafico_tiempos_textos}
graficos.dobles.texto(
  tiempos.texto,
  "Tiempos del cifrado César",
  c(
    "chartr" = "aquamarine3",
    "stringi" = "mediumpurple3"
  )
)
```

## Trabajo con bases de datos

Para esta sección, es importante mencionar que en varios ejercicios se modifica la base de datos en cuestión a un objeto de tipo [data.table](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html), este se trata de una versión más eficiente de los data.frames que R trae por defecto. Además, es necesario mencionar que los data.table tienen una sintaxis similar a SQL.

### Limpieza eficiente

Inicialmente, se procede a descargar la base de datos a utilizar para generar los gráfico, para esto se pondrá en formato [data.table](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html), este se trata de una versión más eficiente de los data.frames que R trae por defecto, es necesario mencionar que los data.table tienen una sintaxis similar a SQL.

Los data.table tienen un operador muy importante que es el [:=](https://stackoverflow.com/questions/7029944/when-should-i-use-the-operator-in-data-table), lo cual mejora en gran medida la eficiencia de muchas operciones.

Además, se usará [chartr](https://www.geeksforgeeks.org/substitute-characters-of-a-string-in-r-programming-chartr-function/) para modificar los caracteres únicos requeridos, pues esta función está optimizada para ese proceso.

De esta manera, se proceden a leer los scripts necesarios para este ejercicio.

```{r scripts_limpieza_eficiente}
# Scripts para la limpieza eficiente
scripts <- c(
  "cod/r/descarga_muertes_cr.R",
  "cod/r/fun_limpieza_df.R",
  "cod/r/fun_limpieza_dt.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se calculan los tiempos de ejecución del ejercicio tanto con DataFrame como con DataTable.

```{r tiempos_limpieza_df}
calcular.tiempos(function()
  limpieza.df(muertes.original))
```

```{r tiempos_limpieza_dt}
calcular.tiempos(function()
  limpieza.dt(muertes.original))
```

Se guardan los resultados en un DataFrame.

```{r tiempos_limpieza}
tiempos.limpieza <-
  df.tiempos.limpieza(
    c(3.05496, 7.309475, 4.02244, 8.529539),
    c(4.77649, 11.26839, 5.891517, 11.31008),
    integrantes = c("Santiago", "Paula", "Eyeri", "Alejandro")
  )
```

Se grafican los tiempos de la limpieza.

```{r graf_tiempos_limpieza}
graficos.dobles.limpieza(
  tiempos.limpieza,
  "Tiempos de limpieza de una base",
  c(
    "Con datatable" = "steelblue2",
    "Sin datatable" = "brown3"
  )
)
```

Se hace lo mismo en Python.

```{python objeto_TrabajoDataframes_Muertes}
obj_Muertes = TrabajoDataframes('data/Muertes_costa_rica.xlsx')
```

```{python medir_limpieza}
obj_Muertes.medir_tiempo("limpiar_datos()")
```

Se crea un objeto de la clase GenerarDataframes el cual se utilizará para los proximos ejercicios

```{python objeto_GenerarDataframes}
obj_generadordf = GenerarDataframes(['Alejandro', 'Eyeri', 'Santiago', 'Paula'])
```

```{python limpieza _tiempos}
df_limpieza = obj_generadordf.tiempos_simples([2.288, 0.828, 0.798, 1.972])
```

```{python grafico limpieza}
GenerarGraficos(df_limpieza).barras('integrante', 'tiempo','Tiempos Limpieza de Datos')
```

### Gráficos en paralelo

Para este ejercicio, primero se realiza la limpieza de la base de datos 'muertes.original'. Posteriormente, se procede a realizar el ejercicio de los gráficos. Para esto se usó el paquete [furrr](https://furrr.futureverse.org), este permite realizar ciclos en paralelo, lo cual se puede observar que aumenta en gran medida la [eficiencia](https://github.com/victorcaquilpan/LecturaExcelConR). Se realizan gráficos de barras para las categóricas e histogramas para las numéricas.

Para empezar, se leen los scripts necesarios para el ejercicio.

```{r scripts_graficos_paralelo}
# Scripts para la limpieza eficiente
scripts <- c(
  "cod/r/limpieza_para_graficos.R",
  "cod/r/ordenar_rango_etario.R",
  "cod/r/fun_histograma.R",
  "cod/r/fun_barras.R",
  "cod/r/setup_graficos_paralelo.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Con lo anterior, probamos el tiempo que tardan las funciones.

```{r calcular_tiempo_graficos}
# Tomamos los tiempos 10 veces e imprimimos los resultados
(microbenchmark(
  future_map(numericos, ~ fun.histograma(muertes.df, .x)),
  future_map(categoricos, ~ fun.barras(muertes.df, .x)),
  times = 10
))
```

Se realiza un DataFrame con el tiempo (en segundos) promedio de los histogramas y de los gráficos de barras, respectivamente.

```{r df_tiempos_graficos}
tiempos.graficos <- df.tiempos.graficos(
  primeros.tiempos = c(8.46395, 4.682311, 8.531366, 10.83528),
  segundos.tiempos = c(13.31152, 7.107419, 14.893497, 16.36664)
)
```

Se grafica lo anterior.

```{r grafico_tiempos_graficar}
graficos.dobles.graf(
  tiempos.graficos,
  "Tiempos de gráficos",
  c(
    "Histogramas" = "khaki3",
    "Gráficos de barras" = "green3"
  )
)
```

Ahora se realiza el ejercicio en Python.

```{python objeto_TrabajoDataframes_Muertes_limpias}
muertes_limpias = TrabajoDataframes('data/Muertes_costa_rica.xlsx').limpiar_datos()
obj_Muertes_limpias = TrabajoDataframes(0)
obj_Muertes_limpias.dataframe = muertes_limpias
```

```{python medir_tiempo_graficos_paralelo}
obj_Muertes.medir_tiempo("generar_graficos()")
```

```{python tiempos_graficos_paralelo}
df_limpieza = obj_generadordf.tiempos_simples([9.71, 8.28, 8.36, 17.07])
```

```{python grafico_graficos_paralelo}
GenerarGraficos(df_limpieza).barras('integrante', 'tiempo','Graficos en paralelo')
```

### Media móvil

Para este ejercicio, se probará un método manual, pues las funciones existentes devuelven aún más nulos de los que hay en el vector original. Para realizar este proceso más rápido se probó a paralelizar el código, pero esto resultó más ineficiente que la versión final.

Primeramente, se leen los scripts necesarios para el ejercicio.

```{r scripts_media_movil}
# Scripts para la media móvil
scripts <- c(
  "cod/r/setup_media_movil.R",
  "cod/r/fun_media_movil.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Con lo anterior, se realizan 10 simulaciones para ver el tiempo promedio.

```{r tiempo_media_movil}
calcular.tiempos(function()
  media.movil(copia.col, 5))
```

Se hace el DataFrame con los valores promedio de cada integrante.

```{r df_tiempos_media_movil}
tiempos.mediam <- df.tiempos.simples(c((3.15827) / 1000,
                                       (2.78863) / 1000,
                                       (10.75752) / 1000,
                                       (30.66207) / 1000
),
c("Santiago", "Eyeri", "Paula", "Alejandro"))
```

En un gráfico.

```{r graf_tiempos_media_movil}
graficos.simples(tiempos.mediam,
                 "darkorchid2",
                 "Tiempos de imputación por media móvil")
```

Se crea un objeto de la clase TrabajoDataframes con la ruta de Base salarios el cual se utilizará para próximos ejercicios.

```{python objeto TrabajoDataframes Base Salarios}
obj_Base_salarios = TrabajoDataframes('data/Base_salarios.xlsx')
```

```{python medir prom movil}
obj_Base_salarios.medir_tiempo("imputar_por_prom_movil('Salario base')")
```

```{python tiempos prom movil}
df_movil = obj_generadordf.tiempos_simples([0.053, 0.034, 0.055, 0.198])
```

```{python grafico prom movil}
GenerarGraficos(df_movil).barras('integrante', 'tiempo', 'Tiempos Imputacion por Media Movil')
```

### Eliminación de columnas por porcentaje de valores nulos

Similar al ejercicio de media móvil, se inicia descargando la base de datos. Luego, se crea la función que hace lo deseado, la cual modifica el DataFrame a un objeto de tipo DataTable, y se mide el tiempo promedio de ejecución usando microbenchmark. Esta función ya hace lo requerido en un tiempo considerablemente rápido, por lo que si fuera posible mejorar el tiempo de ejecución no habría una diferencia significativa.

```{r scripts_eliminar_cols}
# Scripts para la media móvil
scripts <- c(
  "cod/r/setup_eliminar_nulos.R",
  "cod/r/fun_eliminar_cols_df.R",
  "cod/r/fun_eliminar_cols_dt.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Prueba de las funciones.

```{r tiempos_eliminar_cols_df}
calcular.tiempos(function()
  eliminar.columnas.df(base.salarios, 0.01))
```

```{r tiempos_eliminar_cols_dt}
calcular.tiempos(function()
  eliminar.columnas.dt(base.salarios, 0.01))
```

Por último, se hace un DataFrame con los tiempos de ejecución de cada integrante.

```{r df_elimcol}
tiempos.eliminar.columnas <-
  df.tiempos.elimcol(
    c(0.00170, 0.00181, 0.00510, 0.00397),
    c(0.00186, 0.00125, 0.01990, 0.00150),
    c("Eyeri", "Santiago", "Paula", "Alejandro")
  )
```

En gráfico.

```{r grafico_elimcol}
graficos.dobles.elimcols(
  tiempos.eliminar.columnas,
  "Tiempo de eliminación de columnas",
  c(
    "Con datatable" = "indianred3",
    "Sin datatable" = "hotpink2"
  )
)
```

Se hace el ejercicio en Python.

```{python medir eliminar cols}
obj_Base_salarios.medir_tiempo("eliminar_columnas_por_nulos(0.01)")
```

```{python tiempos eliminar cols}
df_elimi_col = obj_generadordf.tiempos_simples([0.0071, 0.0019, 0.0035, 0.0075])
```

```{python grafico eliminar cols}
GenerarGraficos(df_elimi_col).barras('integrante', 'tiempo', 'Tiempos Eliminacion de columnas por valores nulos')
```

### Imputación por agrupación

Para este ejercicio, se inicia realizando la imputación por agrupación de múltiples maneras, iniciando con data.table.

Primeramente, se leen los scripts para este ejercicio.

```{r setup_imputacion_agrupacion}
# Scripts para la imputación por agrupación
scripts <- c(
  "cod/r/setup_imputacion_agrupacion.R",
  "cod/r/fun_agrupacion_df.R",
  "cod/r/fun_agrupacion_dt.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se prueban las funciones.

```{r tiempos_agrupacion_df}
calcular.tiempos(function()
  agrupacion.df(base.salarios))
```

```{r tiempos_agrupacion_dt}
calcular.tiempos(function()
  agrupacion.dt(base.salarios))
```

Se guardan los resultados en un DataFrame.

```{r tiempos_imputacion}
tiempos.agrupacion <- df.tiempos.imputacion(
  primeros.tiempos = c((3.04735) / 1000,
                       (4.2577) / 1000,
                       (5.95827) / 1000 ,
                       (8.804151) / 1000
  ),
  segundos.tiempos = c((7.28283) / 1000,
                       (9.236) / 1000,
                       (15.76346) / 1000 ,
                       (21.437711) / 1000
  ),
  integrantes = c("Santiago", "Eyeri", "Paula", "Alejandro")
)
```

Con un gráfico.

```{r grafico_imputacion}
graficos.dobles.imputacion(
  tiempos.agrupacion,
  "Tiempos de gráficos",
  c(
    "Datatable" = "darkslategray3",
    "Dplyr" = "firebrick3"
  )
)
```

De igual manera, se realiza en Python.

```{python medir impu agrupacion}
obj_Base_salarios.medir_tiempo("imputar_por_agrupacion()")
```

```{python tiempos impu agrupacion}
df_agrupacion = obj_generadordf.tiempos_simples([0.067, 0.022, 0.021, 0,052])
```

```{python grafico impu agrupacion}
GenerarGraficos(df_agrupacion).barras('integrante', 'tiempo', 'Imputacion por agrupacion')
```

## Aplicaciones prácticas

### Regresión logística

Para este ejercicio, se hace la prueba correspondiente del modelo, para esto, se buscó sobre cómo [separar](https://rpubs.com/jboscomendoza/arboles_decision_clasificacion) los datos de un *DataFrame*.

Se leen los scripts para este ejercicio.

```{r setup_reg_log}
# Scripts para la regresión logística
scripts <- c(
  "cod/r/setup_reg_log.R",
  "cod/r/fun_optim.R",
  "cod/r/fun_reg_log.R",
  "cod/r/prueba_reg_log.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se hacen las pruebas de tiempo.

```{r df_tiempos_regresion_logistica}
calcular.tiempos(
  function()
    regresion.logistica(
      X.train = X.train,
      y.train = y.train,
      X.val = X.val,
      y.val = y.val,
      num.iterations = 1000,
      learning.rate = 0.003
    )
)
```

Tiempos de la regresión logística.

```{r tiempos_reg_log}
tiempos.regresion.log <-
  df.tiempos.simples(c(0.08, 0.06, 0.17, 0.23),
                     c("Eyeri", "Santiago", "Paula", "Alejandro"))
```

Gráfico de los tiempos de la regresión logística.

```{r grafico_reg_log}
graficos.simples(tiempos.regresion.log,
                 "deepskyblue2",
                 "Tiempos de la regresión logística")
```

### Modelo estocástico

Se empieza leyendo los scripts para el ejercicio.

```{r setup_modelo_estoc}
# Scripts para el modelo estocástico
scripts <- c(
  "cod/r/setup_modelo_estoc.R",
  "cod/r/fun_primer_falso.R",
  "cod/r/primera_iteracion_modelo_estoc.R",
  "cod/r/fun_iteraciones_estoc.R",
  "cod/r/tiempo_modelo_estocastico.R"
)

# Se leen los scripts
invisible(lapply(scripts, source))
```

Se crea un DataFrame con los tiempos del modelo.

```{r tiempos_modelo_estocastico}
tiempos.estocast <- df.tiempos.simples(c(0.032, 0.046, 0, 0.124),
                                       c("Eyeri", "Santiago", "Paula", "Alejandro"))
```

Gráfico del modelo estocástico.

```{r grafico_modelo_estocástico}
graficos.simples(tiempos.estocast, "pink2", "Tiempos del modelo estocástico")
```

Ahora se hace el ejercicio en Python.

```{python objeto modelo estocastico}
obj_modelo = ModeloEstocastico('data/Mortalidad_supen.xlsx', 'Sexo_1_limpio')
```

```{python medir modelo estocastico}
obj_modelo.calcular_tiempo_promedio()
```

```{python tiempos modelo estocastico}
df_modelo = obj_generadordf.tiempos_simples([0.05, 0.02, 0.02, 0,03])
```

```{python grafico modelo estocastico}
GenerarGraficos(df_modelo).barras('integrante', 'tiempo','Modelo estocastico')
```


