{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320f8cc1-7cb5-4a63-884b-2c3b2c9c2458",
   "metadata": {},
   "source": [
    "# Proyecto Herramientas II - Grupo Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ee1d8-6927-4e75-91c5-fab6bc9612be",
   "metadata": {},
   "source": [
    "Primeramente se presentan las librerías que se utilizaron y que son necesarias para ejecutar el código. Se deja como comentarios la instalación de las mismas por si alguien ocupara instalar alguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c01ba81-d302-4682-88e9-4680e349460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install numexpr\n",
    "# !pip install numba\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install joblib\n",
    "# !pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d1f6f8-7878-40f9-90cc-1792560e7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan las librerías más comúnes que se van a usar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import timeit # La librería timeit no requiere ser instalada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9bdd5c-8ed0-4483-88d0-8468dc2efa11",
   "metadata": {},
   "source": [
    "Se usó la librería timeit para determinar el tiempo de ejecución de los ejercicios.\n",
    "\n",
    "Referencias:\n",
    "\n",
    "https://docs.python.org/es/3/library/timeit.html\n",
    "\n",
    "https://www.geeksforgeeks.org/timeit-python-examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43d3d5-44f3-42e5-bc1f-83c1829e9150",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Operaciones matriciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b6166b-3be5-4a6f-98d0-877a273f3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la matriz con la que se va a trabajar\n",
    "matriz = np.random.rand(10_000, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1c473a-264b-4a85-8e38-a9232a128d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.658074340003077"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicialmente se realiza el ejercicio usando la librería NumExpr\n",
    "import numexpr as ne\n",
    "\n",
    "# Se crea un string con el código que se quiere ejecutar\n",
    "codigo = \"\"\"\n",
    "resultado = ne.evaluate('(matriz ** 100) * 10 + 5')\n",
    "\"\"\"\n",
    "\n",
    "# Se ejecuta el código 10 veces usando timeit y se almacenan los tiempos en una lista\n",
    "tiempo_total_ej_1 = timeit.timeit(stmt = codigo, number = 10, globals = globals())\n",
    "\n",
    "# Se calcula el tiempo promedio\n",
    "tiempo_promedio_ej_1 = tiempo_total_ej_1 / 10\n",
    "\n",
    "tiempo_promedio_ej_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e60aeb-d781-4668-8ffb-d66ee9a8ea0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2608035699930042"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seguidamente se hace lo mismo usando la librería Numba\n",
    "import numba as nb\n",
    "\n",
    "# Se crea una función que realice la operación que queramos, agregándole decoradores para que numba compile esta función de manera eficiente \n",
    "@nb.njit(parallel = True)\n",
    "def operacion(matriz):\n",
    "    \n",
    "    matriz_resultado = np.empty_like(matriz)\n",
    "    \n",
    "    for i in nb.prange(matriz.shape[0]):\n",
    "        \n",
    "        for j in range(matriz.shape[1]):\n",
    "            \n",
    "            matriz_resultado[i, j] = (matriz[i, j] ** 100) * 10 + 5\n",
    "            \n",
    "    return matriz_resultado\n",
    "\n",
    "codigo_ej_1 = \"\"\"\n",
    "resultado = operacion(matriz)\n",
    "\"\"\"\n",
    "\n",
    "tiempo_total_ej_1 = timeit.timeit(stmt = codigo_ej_1, number = 10, globals = globals())\n",
    "\n",
    "tiempo_promedio_ej_1 = tiempo_total_ej_1 / 10\n",
    "\n",
    "tiempo_promedio_ej_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65853fbd-2fe3-47d9-a0c0-f87ae7449388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integrante</th>\n",
       "      <th>numexpr</th>\n",
       "      <th>numba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eyeri</td>\n",
       "      <td>0.61500</td>\n",
       "      <td>0.22180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alejandro</td>\n",
       "      <td>2.38700</td>\n",
       "      <td>0.73300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santiago</td>\n",
       "      <td>0.34238</td>\n",
       "      <td>0.24621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paula</td>\n",
       "      <td>2.34700</td>\n",
       "      <td>0.46500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  integrante  numexpr    numba\n",
       "0      Eyeri  0.61500  0.22180\n",
       "1  Alejandro  2.38700  0.73300\n",
       "2   Santiago  0.34238  0.24621\n",
       "3      Paula  2.34700  0.46500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Por último, se crea un dataframe con el tiempo promedio (en segundos) obtenido por cada uno de los integrantes usando cada librería\n",
    "\n",
    "data_ej_1 = {\n",
    "\n",
    "    'integrante': ['Eyeri', 'Alejandro', 'Santiago', 'Paula'],\n",
    "\n",
    "    'numexpr': [0.615, 2.387, 0.34238, 2.347],\n",
    "\n",
    "    'numba': [0.2218, 0.733, 0.24621, 0.465]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_1 = pd.DataFrame(data_ej_1)\n",
    "tiempos_ej_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8f0833-b7bf-4a53-8be1-e2a3be120a6d",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Limpieza de bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef1912a-dc13-4679-ae31-60e7fa036452",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimeit\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m muertes_cr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Muertes_costa_rica.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                                engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m copia_muertes \u001b[38;5;241m=\u001b[39m muertes_cr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlimpiar_datos\u001b[39m():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engines[engine](\n\u001b[0;32m   1568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io,\n\u001b[0;32m   1569\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1570\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   1571\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 553\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    554\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    556\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    557\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:573\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, engine_kwargs)\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:572\u001b[0m, in \u001b[0;36mOpenpyxlReader.load_workbook\u001b[1;34m(self, filepath_or_buffer, engine_kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[0;32m    570\u001b[0m default_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep_links\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_workbook(\n\u001b[0;32m    573\u001b[0m     filepath_or_buffer,\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(default_kwargs \u001b[38;5;241m|\u001b[39m engine_kwargs),\n\u001b[0;32m    575\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\openpyxl\\reader\\excel.py:344\u001b[0m, in \u001b[0;36mload_workbook\u001b[1;34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_workbook\u001b[39m(filename, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba\u001b[38;5;241m=\u001b[39mKEEP_VBA,\n\u001b[0;32m    315\u001b[0m                   data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    :param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     reader \u001b[38;5;241m=\u001b[39m ExcelReader(filename, read_only, keep_vba,\n\u001b[0;32m    345\u001b[0m                          data_only, keep_links, rich_text)\n\u001b[0;32m    346\u001b[0m     reader\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mwb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\openpyxl\\reader\\excel.py:123\u001b[0m, in \u001b[0;36mExcelReader.__init__\u001b[1;34m(self, fn, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba\u001b[38;5;241m=\u001b[39mKEEP_VBA,\n\u001b[0;32m    122\u001b[0m              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive \u001b[38;5;241m=\u001b[39m _validate_archive(fn)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_only \u001b[38;5;241m=\u001b[39m read_only\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\site-packages\\openpyxl\\reader\\excel.py:95\u001b[0m, in \u001b[0;36m_validate_archive\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     88\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl does not support \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m file format, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease check you can open \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mit with Excel first. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupported formats are: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m (file_format,\n\u001b[0;32m     92\u001b[0m                                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SUPPORTED_FORMATS))\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidFileException(msg)\n\u001b[1;32m---> 95\u001b[0m archive \u001b[38;5;241m=\u001b[39m ZipFile(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m archive\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\zipfile\\__init__.py:1349\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1349\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_RealGetContents()\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1352\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\Lib\\zipfile\\__init__.py:1416\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "muertes_cr = pd.read_excel('data/Muertes_costa_rica.xlsx',\n",
    "                               engine = 'openpyxl')\n",
    "\n",
    "copia_muertes = muertes_cr.copy()\n",
    "\n",
    "def limpiar_datos():\n",
    "\n",
    "    global muertes_cr\n",
    "\n",
    "    muertes_cr = copia_muertes.copy()\n",
    "    \n",
    "    muertes_cr = muertes_cr.drop(columns = ['pc', 'causamuer', 'des_causa', 'instmurio', 'pcocu', 'nacmadre', 'pcregis', 'gruposcb'])\n",
    "    \n",
    "    # Se realiza la limpieza de la base de datos\n",
    "    \n",
    "    muertes_cr = muertes_cr[muertes_cr['edads'] >= 15]\n",
    "    \n",
    "    muertes_cr = muertes_cr[muertes_cr['anodef'] >= 2014]\n",
    "    \n",
    "    muertes_cr = muertes_cr[muertes_cr['anotrab'] >= 2014]\n",
    "    \n",
    "    muertes_cr = muertes_cr[muertes_cr['anodeclara'] >= 2014]\n",
    "    \n",
    "    muertes_cr['estcivil'] = muertes_cr['estcivil'].str.replace(\"Ã³\", \"o\")\n",
    "    \n",
    "    muertes_cr['ocuparec'] = muertes_cr['ocuparec'].str.replace(\"Ã¡\", \"a\")\n",
    "    \n",
    "    muertes_cr['ocuparec'] = muertes_cr['ocuparec'].str.replace(\"Ã©\", \"e\")\n",
    "    \n",
    "    muertes_cr['ocuparec'] = muertes_cr['ocuparec'].str.replace(\"Ã\", \"i\")\n",
    "    \n",
    "    muertes_cr['regsalud'] = muertes_cr['regsalud'].str.replace(\"Ã\\xad\", \"i\")\n",
    "    \n",
    "    muertes_cr['regsalud'] = muertes_cr['regsalud'].str.replace(\"Ã³\", \"o\")\n",
    "    \n",
    "    muertes_cr['provincia'] = muertes_cr['provincia'].str.replace(\"Ã©\", \"e\")\n",
    "    \n",
    "    muertes_cr['provincia'] = muertes_cr['provincia'].str.replace(\"Ã³\", \"o\")\n",
    "    \n",
    "    muertes_cr['provocu'] = muertes_cr['provocu'].str.replace(\"Ã©\", \"e\")\n",
    "    \n",
    "    muertes_cr['provocu'] = muertes_cr['provocu'].str.replace(\"Ã³\", \"o\")\n",
    "    \n",
    "    muertes_cr['provregis'] = muertes_cr['provregis'].str.replace(\"Ã©\", \"e\")\n",
    "    \n",
    "    muertes_cr['provregis'] = muertes_cr['provregis'].str.replace(\"Ã³\", \"o\")\n",
    "    \n",
    "    muertes_cr['reginec'] = muertes_cr['reginec'].str.replace(\"Ã\\xad\", \"i\")\n",
    "    \n",
    "    muertes_cr['reginec'] = muertes_cr['reginec'].str.replace(\"Ã³\", \"o\")\n",
    "    \n",
    "    muertes_cr['edadsrec'] = muertes_cr['edadsrec'].str.replace(\"100 y mÃ¡s\", \"100 - 121\")\n",
    "    \n",
    "    muertes_cr['autopsia'] = muertes_cr['autopsia'].str.replace(\"Ã©\", \"e\")\n",
    "    \n",
    "    muertes_cr['autopsia'] = muertes_cr['autopsia'].str.replace(\"Ã\\xad\", \"i\")\n",
    "    \n",
    "    muertes_cr['asistmed'] = muertes_cr['asistmed'].str.replace(\"Ã©\", \"e\")\n",
    "    \n",
    "    muertes_cr['asistmed'] = muertes_cr['asistmed'].str.replace(\"Ã\\xad\", \"i\")\n",
    "    \n",
    "    muertes_cr['nacionalid'] = muertes_cr['nacionalid'].apply(lambda x: 'Extranjero' if x != 'Costa Rica' else x)\n",
    "    \n",
    "    otros = ['Ignorado', 'Union libre', 'Separado', 'Menor']\n",
    "    \n",
    "    muertes_cr['estcivil'] = muertes_cr['estcivil'].replace(otros, 'Otros')\n",
    "    \n",
    "    trabajadores_activos = ['Profesionales cienti\\xadficos e intelectuales', \n",
    "                            'Agricultores y trabajadores calificados agropecuarios, forestales y pesqueros',\n",
    "                            'Ocupaciones elementales', 'Trabajadores de los servicios y vendedores de comercios y mercados',\n",
    "                            'Operadores de instalaciones y maquinas y ensambladores', 'Tecnicos y profesionales de nivel medio',\n",
    "                            'Oficiales, operarios y artesanos de artes mecanicas y de otros oficios', 'Personal de apoyo administrativo',\n",
    "                            'Directores y gerentes']\n",
    "    \n",
    "    muertes_cr['ocuparec'] = muertes_cr['ocuparec'].replace(trabajadores_activos, 'Trabajadores activos')\n",
    "    \n",
    "    otros = ['Pensionado', 'Persona con discapacidad', 'Estudiante', 'Mal especificadas', 'Privado de libertad']\n",
    "    \n",
    "    muertes_cr['ocuparec'] = muertes_cr['ocuparec'].replace(otros, 'Otros')\n",
    "    \n",
    "    rangos_etarios = [\"15 - 19\", \"20 - 24\", \"25 - 29\", \"30 - 34\", \"35 - 39\", \"40 - 44\", \"45 - 49\", \n",
    "                      \"50 - 54\", \"55 - 59\", \"60 - 64\", \"65 - 69\", \"70 - 74\", \"75 - 79\", \"80 - 84\", \n",
    "                      \"85 - 89\", \"90 - 94\", \"95 - 99\", \"100 - 121\"]\n",
    "    \n",
    "    muertes_cr['edadsrec'] = pd.Categorical(muertes_cr['edadsrec'], categories = rangos_etarios, ordered = True)\n",
    "    \n",
    "    muertes_cr.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return muertes_cr\n",
    "\n",
    "tiempo_total_ej_2 = timeit.timeit(stmt = limpiar_datos, number = 10)\n",
    "\n",
    "tiempo_promedio_ej_2 = tiempo_total_ej_2 / 10\n",
    "\n",
    "tiempo_promedio_ej_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f38361-11e4-4a4f-a340-b3adf49f624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_2 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "\n",
    "    'tiempo_promedio': [2.288, 0.8281, 0.79793, 1.972]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_2 = pd.DataFrame(data_ej_2)\n",
    "tiempos_ej_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02787c5-3ea5-4700-8c16-cebd1d930a0c",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Gráficos en paralelo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fb011-7420-4d6b-9ff5-bd5ab7769d8d",
   "metadata": {},
   "source": [
    "Primeramente se usa joblib para paralelizar la generación de los histogramas y de los gráficos de barras, por medio de los componentes Parallel y delayed\n",
    "\n",
    "Referencias:\n",
    "\n",
    "https://joblib.readthedocs.io/en/latest/parallel.html\n",
    "\n",
    "https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html\n",
    "\n",
    "También se hace uso de la función clear_output del módulo IPython, con el fin de limpiar la salida de la celda y no mostrar todos los gráficos\n",
    "generados cada vez que se ejecuta la función de generar gráficos\n",
    "\n",
    "Referencias:\n",
    "\n",
    "https://stackoverflow.com/questions/24816237/ipython-notebook-clear-cell-output-in-code\n",
    "\n",
    "https://notebook.community/CestDiego/emacs-ipython-notebook/tests/notebook/nbformat4/Animations%20Using%20clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc47c9-7f03-4080-adc9-9a513d50c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Se define una función que realice los histogramas para las variables numéricas\n",
    "def histograma(df, columna):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    sns.histplot(df[columna], bins = 'auto', color = 'blue', edgecolor = 'black')\n",
    "    \n",
    "    plt.xlabel('Valor')\n",
    "    \n",
    "    plt.ylabel('Frecuencia')\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "# Se define otra función que haga los gráficos de barras para las variables categóricas\n",
    "def barras(df, columna):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    sns.countplot(x = columna, data = df, color = 'red')\n",
    "\n",
    "    plt.xticks(rotation = 45)\n",
    "    \n",
    "    plt.xlabel('Categorías')\n",
    "    \n",
    "    plt.ylabel('Cantidad')\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "# Definimos una función que devuelve las columnas numéricas y categóricas en listas por aparte\n",
    "def tipos_columnas(df):\n",
    "    \n",
    "    numericas = df.select_dtypes(include = ['number']).columns\n",
    "        \n",
    "    categoricas = df.select_dtypes(include = ['object', 'category']).columns\n",
    "\n",
    "    return numericas, categoricas\n",
    "\n",
    "# Obtenemos las variables numericas y categóricas\n",
    "numericas, categoricas = tipos_columnas(muertes_cr)\n",
    "\n",
    "# Definimos una función que genere los gráficos deseados\n",
    "def generar_graficos(limpiar = True):\n",
    "\n",
    "    # Generamos y guardamos los gráficos tanto de histogramas como de barras usando la paralelización de joblib\n",
    "    histogramas = Parallel(n_jobs = -1)(\n",
    "    \n",
    "        delayed(histograma)(muertes_cr, col) for col in numericas\n",
    "    \n",
    "    )\n",
    "\n",
    "    graficos_barras = Parallel(n_jobs = -1)(\n",
    "    \n",
    "        delayed(barras)(muertes_cr, col) for col in categoricas\n",
    "    \n",
    "    )\n",
    "\n",
    "    # Mostramos los gráficos\n",
    "    for grafico in histogramas + graficos_barras:\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Si el parámetro limpiar es True, no se mostrarán los gráficos\n",
    "    if limpiar:\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "# Así, se mide el tiempo que tarda la función al ejecutarla 10 veces\n",
    "tiempo_ejecucion_ej_3 = timeit.timeit(generar_graficos, number = 10)\n",
    "\n",
    "# Se obtiene el tiempo promedio de las 10 ejecuciones\n",
    "tiempo_promedio_ej_3 = tiempo_ejecucion_ej_3 / 10\n",
    "tiempo_promedio_ej_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9aa94f-0984-4100-98bc-ee7d56778026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último, se crea un dataframe con el tiempo promedio que tardó la función por cada integrante\n",
    "data_ej_3 = {\n",
    "\n",
    "    'integrante': ['Eyeri', 'Alejandro', 'Santiago', 'Paula'],\n",
    "\n",
    "    'tiempo_promedio': [8.28, 9.71, 8.3582, 17.071]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_3 = pd.DataFrame(data_ej_3)\n",
    "tiempos_ej_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231c278-2850-4807-b1d5-b05609f02600",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Media móvil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2784ee-49f2-4f9d-aeba-a8e686caa4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel = True)\n",
    "def imputar_valores_nulos(data, banda):\n",
    "    \n",
    "    n = len(data)\n",
    "    \n",
    "    resultado = data.copy()\n",
    "    \n",
    "    for i in prange(n):\n",
    "        \n",
    "        if np.isnan(data[i]):\n",
    "            \n",
    "            principio = max(0, i - banda)\n",
    "            \n",
    "            final = min(n, i + banda + 1)\n",
    "            \n",
    "            suma, cuenta = 0.0, 0\n",
    "            \n",
    "            for j in range(principio, final):\n",
    "                \n",
    "                if not np.isnan(data[j]):\n",
    "                    \n",
    "                    suma += data[j]\n",
    "                    \n",
    "                    cuenta += 1\n",
    "                    \n",
    "            if cuenta > 0:\n",
    "                \n",
    "                resultado[i] = suma / cuenta\n",
    "                \n",
    "    return resultado\n",
    "\n",
    "def imputar_por_prom_movil(dataframe, columna, banda):\n",
    "\n",
    "    data = dataframe[columna].values\n",
    "    \n",
    "    data_imputado = imputar_valores_nulos(data, banda)\n",
    "    \n",
    "    dataframe[columna] = data_imputado\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec0ca1-72c5-4a9c-9047-d4af04a608b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_salarios = pd.read_excel('data/Base_salarios.xlsx',\n",
    "                               engine = 'openpyxl')\n",
    "\n",
    "codigo_ej_4 = \"\"\"\n",
    "resultado = imputar_por_prom_movil(base_salarios, 'Salario base', 4)\n",
    "\"\"\"\n",
    "\n",
    "tiempo_total_ej_4 = timeit.timeit(stmt = codigo_ej_4, number = 10, globals = globals())\n",
    "\n",
    "tiempo_promedio_ej_4 = tiempo_total_ej_4 / 10\n",
    "\n",
    "tiempo_promedio_ej_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609a773-be3d-4c81-997f-86e01ec3c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_4= {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "\n",
    "    'tiempo_promedio': [0.053, 0.03388, 0.0553, 0.1978]\n",
    "\n",
    "}\n",
    "\n",
    "tiempos_ej_4 = pd.DataFrame(data_ej_4)\n",
    "tiempos_ej_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5d516-6c9a-4275-b447-94ffc010e163",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Eliminar columnas por porcentaje de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecc265-6d26-4f84-a025-ed62a83dfc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def eliminar_columnas_por_nulos(df, porcentaje):\n",
    "    \n",
    "    # Calculamos el número máximo de valores nulos permitidos\n",
    "    max_nulos = len(df) * porcentaje\n",
    "    \n",
    "    # Filtramos las columnas que tienen menos de max_nulos valores nulos\n",
    "    df_filtrado = df.dropna(axis=1, thresh=len(df) - max_nulos)\n",
    "    \n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb1d02-3382-4b1e-84ac-0a96f8d0f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_salarios = pd.read_excel('data/Base_salarios.xlsx',\n",
    "                               engine = 'openpyxl')\n",
    "\n",
    "codigo_ej_5 = \"\"\"\n",
    "base_salarios_filtrada = eliminar_columnas_por_nulos(base_salarios, 0.01)\n",
    "\"\"\"\n",
    "\n",
    "tiempo_total_ej_5 = timeit.timeit(stmt = codigo_ej_5, number = 10, globals = globals())\n",
    "\n",
    "tiempo_promedio_ej_5 = tiempo_total_ej_5 / 10\n",
    "\n",
    "tiempo_promedio_ej_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ddc1d-2db5-445d-ba25-7fbe784d5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_5 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "    \n",
    "    'tiempo_promedio': [0.0071, 0.0019, 0.0035, 0.0075]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_5 = pd.DataFrame(data_ej_5)\n",
    "tiempos_ej_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b69356-1efb-4078-b64e-cfd67241f4cf",
   "metadata": {},
   "source": [
    "## Ejercicio 6: Imputacion por agrupación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f9a1c-5db8-4be9-bae3-efe0adcfbf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_salarios = pd.read_excel('data/Base_salarios.xlsx',\n",
    "                               engine = 'openpyxl')\n",
    "\n",
    "# Función para imputar valores nulos por agrupación\n",
    "def imputar_por_agrupacion():\n",
    "    \n",
    "    # Imputación utilizando pandas\n",
    "    base_salarios['Salario base'] = base_salarios.groupby(['Género', 'Grado de estudio'])['Salario base'] \\\n",
    "                           .transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    return base_salarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837725b4-5090-4dec-a9c1-e95b91f02349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Así, se mide el tiempo que tarda la función al ejecutarla 10 veces\n",
    "tiempo_total_ej_6 = timeit.timeit(imputar_por_agrupacion, number = 10)\n",
    "\n",
    "# Se obtiene el tiempo promedio de las 10 ejecuciones\n",
    "tiempo_promedio_ej_6 = tiempo_total_ej_6 / 10\n",
    "tiempo_promedio_ej_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409818c-e6fe-4dd3-98c9-d73a4631348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_6 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "    \n",
    "    'tiempo_promedio': [0.0668, 0.0224, 0.02082, 0.0515]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_6 = pd.DataFrame(data_ej_6)\n",
    "tiempos_ej_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571bb30-7ca9-4b8d-9a9a-ffa871ef01b8",
   "metadata": {},
   "source": [
    "## Ejercicio 7: Producto acumulado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af4a5b-a880-44e6-b80c-925538dcd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductoAcumulado:\n",
    "    \n",
    "    def __init__(self, lista):\n",
    "        \n",
    "        self.__lista = np.array(lista)\n",
    "    \n",
    "    def calcular_producto_acumulado(self):\n",
    "        \n",
    "        return np.cumprod(self.__lista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cebc6e-3543-4b34-8a2b-9a13294bad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo_ej_7 = \"\"\"\n",
    "lista = np.random.uniform(0, 2, 10000000).tolist()\n",
    "\n",
    "ejemplo = ProductoAcumulado(lista)\n",
    "\n",
    "ejemplo.calcular_producto_acumulado()\n",
    "\"\"\"\n",
    "\n",
    "tiempo_total_ej_7 = timeit.timeit(stmt = codigo_ej_7, number = 10, globals = globals())\n",
    "\n",
    "tiempo_promedio_ej_7 = tiempo_total_ej_7 / 10\n",
    "\n",
    "tiempo_promedio_ej_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2bba4-7891-47a6-9462-24175ddb83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variante con Numba\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "class ProductoAcumuladoNumba:\n",
    "    \n",
    "    def __init__(self, lista):\n",
    "        \n",
    "        self.__lista = np.array(lista)\n",
    "    \n",
    "    def calcular_producto_acumulado(self):\n",
    "            \n",
    "        return self._producto_acumulado(self.__lista)\n",
    "\n",
    "    @staticmethod\n",
    "    @jit(nopython = True)\n",
    "    def _producto_acumulado(array):\n",
    "        \n",
    "        result = np.ones_like(array)\n",
    "        \n",
    "        result[0] = array[0]\n",
    "        \n",
    "        for i in range(1, len(array)):\n",
    "            \n",
    "            result[i] = result[i - 1] * array[i]\n",
    "        \n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce70d94-366d-4948-86dc-6e249023b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo_ej_7 = \"\"\"\n",
    "lista = np.random.uniform(0, 2, 10000000).tolist()\n",
    "\n",
    "ejemplo = ProductoAcumuladoNumba(lista)\n",
    "\n",
    "ejemplo.calcular_producto_acumulado()\n",
    "\"\"\"\n",
    "\n",
    "tiempo_total_ej_7 = timeit.timeit(stmt = codigo_ej_7, number = 10, globals = globals())\n",
    "\n",
    "tiempo_promedio_ej_7 = tiempo_total_ej_7 / 10\n",
    "\n",
    "tiempo_promedio_ej_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d01e8-691e-4500-91d2-235c8025d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_7 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "    \n",
    "    'tiempo_promedio_original': [1.318, 0.693, 0, 0],\n",
    "\n",
    "    'tiempo_promedio_numba': [1.424, 0.719, 0, 0]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_7 = pd.DataFrame(data_ej_7)\n",
    "tiempos_ej_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bec5ea-3961-4434-b0a7-209190afc097",
   "metadata": {},
   "source": [
    "## Ejercicio 8: Cifrado César"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2944c-193b-43ff-8f51-b0beccea39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifradoCesar:\n",
    "    \n",
    "    def __init__(self, cadena):\n",
    "        \n",
    "        self.__cadena = cadena\n",
    "    \n",
    "    \n",
    "    def desplazar_letras(self, n):\n",
    "        \n",
    "        desplazada = []\n",
    "        \n",
    "        for char in self.__cadena:\n",
    "            \n",
    "            if char.isalpha():\n",
    "                \n",
    "                start = ord('a') if char.islower() else ord('A')\n",
    "                \n",
    "                desplazada.append(chr(start + (ord(char) - start + n) % 26))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                desplazada.append(char)\n",
    "                \n",
    "        cadena_desplazada = ''.join(desplazada)\n",
    "        \n",
    "        return cadena_desplazada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f9666-efa0-4780-a358-23f46a6646c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo_ej_8 = \"\"\"\n",
    "with open('data/El_principito.txt', 'r') as file:\n",
    "    contenido = file.read()\n",
    "\n",
    "cambiador = CifradoCesar(contenido)\n",
    "\n",
    "\n",
    "cadena_desplazada = cambiador.desplazar_letras(5)\n",
    "\"\"\"\n",
    "\n",
    "tiempo_total_ej_8 = timeit.timeit(stmt = codigo_ej_8, number = 10, globals = globals())\n",
    "\n",
    "tiempo_promedio_ej_8 = tiempo_total_ej_8 / 10\n",
    "\n",
    "tiempo_promedio_ej_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83182a78-536a-4610-b1af-42f1db8afd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_8 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "    \n",
    "    'tiempo_promedio': [0.035, 0.013, 0, 0]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_8 = pd.DataFrame(data_ej_8)\n",
    "tiempos_ej_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92374eb4-8efb-4ca8-b387-db5b3fe53ac8",
   "metadata": {},
   "source": [
    "## Ejercicio 9: Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600d3c2-dd78-43aa-8b0f-262c9887ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython = True)\n",
    "def funcion_sigmoide(z):\n",
    "\n",
    "    '''\n",
    "    Función que le aplica la función sigmoide al parámetro dado.\n",
    "    Esta función matemática lo que hace es convertir un valor real en un valor\n",
    "    en el intervalo [0, 1]. Es comúnmente utilizada como función de activación \n",
    "    en modelos de regresión logística y redes neuronales.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    z: numpy.ndarray\n",
    "       escalar, vector o matriz a la que se le quiere aplicar la función sigmoide\n",
    "       \n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        escalar, vector o matriz resultante después de aplicarle la función sigmoide\n",
    "        al elemento o a los elementos del parámetro dado \n",
    "    '''\n",
    "    \n",
    "    return 1 / (1 + np.exp(-z)) # Se calcula el resultado de la función sigmoide \n",
    "                                # evaluada en el elemento o los elementos del parámetro dado\n",
    "\n",
    "@jit(nopython = True)\n",
    "def propagacion_adelante(W, b, X):\n",
    "\n",
    "    '''\n",
    "    Función que realiza la propagación hacia adelante de un modelo de regresión logística.\n",
    "    En este proceso se combinan las características de entrada con los pesos del modelo y \n",
    "    se aplica una función de activación (en este caso, la función sigmoide) para obtener \n",
    "    las predicciones del modelo.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    W: numpy.ndarray\n",
    "       matriz de tamaño (1, numero_de_caracteristicas) que contiene los pesos del modelo\n",
    "\n",
    "    b: float\n",
    "       sesgo del modelo\n",
    "    \n",
    "    X: numpy.ndarray\n",
    "       matriz de tamaño (numero_de_muestras, numero_de_caracteristicas) que contiene \n",
    "       las características de las muestras de entrada\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    A: numpy.ndarray\n",
    "       matriz de tamaño (1, numero_de_muestras) que contiene las salidas del \n",
    "       modelo después de aplicar la función sigmoide\n",
    "    '''\n",
    "    \n",
    "    Z = np.dot(W, X.T) + b # Se realiza la combinación lineal de las entradas con los pesos y el sesgo\n",
    "    \n",
    "    A = funcion_sigmoide(Z) # Se aplica la función sigmoide a lo calculado anteriormente\n",
    "    \n",
    "    return A\n",
    "\n",
    "@jit(nopython = True)\n",
    "def propagacion_atras(X, A, y):\n",
    "\n",
    "    '''\n",
    "    Función que calcula la propagación hacia atrás para actualizar los gradientes.\n",
    "    Este proceso calcula los gradientes de la función de costo con respecto a los \n",
    "    parámetros del modelo (en este caso, los pesos  el sesgo), lo que permite ajustar \n",
    "    estos parámetros de manera que el modelo se ajuste mejor a los datos de entrenamiento.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X: numpy.ndarray\n",
    "       matriz de tamaño (numero_de_muestras, numero_de_caracteristicas) que contiene \n",
    "       las características de las muestras de entrada\n",
    "\n",
    "    A: numpy.ndarray\n",
    "       matriz de tamaño (1, numero_de_muestras) calculada en la propagación hacia adelante,\n",
    "       que contiene las salidas del modelo después de aplicar la función sigmoide\n",
    "\n",
    "    y: numpy.ndarray\n",
    "       vector de tamaño (numero_de_muestras) que contiene las etiquetas verdaderas \n",
    "       para las muestras de entrada\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    dW : numpy.ndarray\n",
    "         gradiente del costo respecto a los pesos W\n",
    "         \n",
    "    db : float\n",
    "         gradiente del costo respecto al sesgo b\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0] # Número de muestras\n",
    "    \n",
    "    dZ = A - y # Gradiente de la función de activación respecto a la función de costo\n",
    "    \n",
    "    dW = np.dot(dZ, X) / m # Se calcula el gradiente del costo con respecto a los pesos W\n",
    "    \n",
    "    db = np.sum(dZ) / m # Se calcula el gradiente del costo con respecto al sesgo b\n",
    "    \n",
    "    return dW, db\n",
    "\n",
    "@jit(nopython = True)\n",
    "def optimizar(W, b, X, y, num_iterations, learning_rate):\n",
    "\n",
    "    '''\n",
    "    Función que optimiza los parámetros W y b del modelo de regresión logística mediante el descenso de gradiente.\n",
    "    El descenso de gradiente es un algoritmo de optimización que consiste en ajustar iterativamente los parámetros \n",
    "    de un modelo en la dirección opuesta al gradiente de la función de costo con respecto a los parámetros, \n",
    "    lo cual optimiza y, por lo tanto, minimiza dicha función de costo al ajustar de mejor manera estos parámetros.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    W: numpy.ndarray\n",
    "       matriz de tamaño (1, numero_de_caracteristicas) que contiene los pesos del modelo\n",
    "\n",
    "    b: float\n",
    "       sesgo del modelo\n",
    "    \n",
    "    X: numpy.ndarray\n",
    "       matriz de tamaño (numero_de_muestras, numero_de_caracteristicas) que contiene \n",
    "       las características de las muestras de entrada\n",
    "\n",
    "    y: numpy.ndarray\n",
    "       vector de tamaño (numero_de_muestras) que contiene las etiquetas verdaderas \n",
    "       para las muestras de entrada\n",
    "\n",
    "    num_iterations: int\n",
    "                    número de iteraciones del descenso de gradiente\n",
    "\n",
    "    learning_rate: float\n",
    "                   tasa de aprendizaje para actualizar los parámetros\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    params : dict\n",
    "             diccionario que contiene los parámetros optimizados:\n",
    "             - \"W\": Matriz de pesos optimizada\n",
    "             - \"b\": Sesgo optimizado\n",
    "    '''\n",
    "\n",
    "    # Se itera sobre el número especificado de iteraciones\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Se hace la propagación hacia adelante para calcular la activación \n",
    "        # y el costo con los parámetros actuales\n",
    "        A = propagacion_adelante(W, b, X)\n",
    "\n",
    "        # Se hace la propagación hacia atrás para calcular los gradientes de\n",
    "        # los parámetros actuales\n",
    "        dW, db = propagacion_atras(X, A, y)\n",
    "\n",
    "        # Se actualizan los parámetros (pesos y sesgo) utilizando el descenso de gradiente\n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "            \n",
    "    return W, b\n",
    "\n",
    "@jit(nopython = True)\n",
    "def predecir(W, b, X):\n",
    "\n",
    "    '''\n",
    "    Función que realiza predicciones de clases binarias utilizando los parámetros optimizados.\n",
    "    El objetivo de este proceso es predecir la pertenencia de las muestras a una de las dos \n",
    "    clases posibles. Esto consiste en hacer las predicciones de clase para las muestras en X, \n",
    "    donde cada predicción es una asignación binaria en la que se estima si una muestra pertenece \n",
    "    a la clase 1 o a la clase 0 basada en la probabilidad calculada por el modelo.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    W: numpy.ndarray\n",
    "       matriz de tamaño (1, numero_de_caracteristicas) que contiene los pesos del modelo\n",
    "\n",
    "    b: float\n",
    "       sesgo del modelo\n",
    "    \n",
    "    X: numpy.ndarray\n",
    "       matriz de tamaño (numero_de_muestras, numero_de_caracteristicas) que contiene \n",
    "       las características de las muestras de entrada\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    y_prediction: numpy.ndarray\n",
    "                  vector de predicciones de tamaño (1, numero_de_muestras), donde cada elemento es 1 o 0\n",
    "                  dependiendo de si la probabilidad en esa predicción es mayor a 0.5 o no\n",
    "    '''\n",
    "    \n",
    "    Z = np.dot(W, X.T) + b # Se realiza la combinación lineal de las entradas con los pesos y el sesgo\n",
    "    \n",
    "    A = funcion_sigmoide(Z) # Se aplica la función sigmoide a lo calculado anteriormente\n",
    "    \n",
    "    return np.where(A > 0.5, 1, 0) # Se le asigna un 1 a las predicciones donde la probabilidad es mayor que 0.5, y un 0 en caso contrario\n",
    "\n",
    "@jit(nopython = True)\n",
    "def regresion_logistica(X_train, y_train, X_val, y_val, num_iterations = 2000, learning_rate = 0.5):\n",
    "\n",
    "    '''\n",
    "    Función que entrena un modelo de regresión logística y evalúa su rendimiento mediante\n",
    "    el cálculo de los ajustes de los conjuntos de entrenamiento y testeo.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X_train: numpy.ndarray\n",
    "            matriz de características de entrenamiento del modelo\n",
    "             \n",
    "    y_train: numpy.ndarray\n",
    "             vector de etiquetas de entrenamiento\n",
    "\n",
    "    X_val: numpy.ndarray\n",
    "           matriz de características de testeo del modelo\n",
    "\n",
    "    y_val: numpy.ndarray\n",
    "           vector de etiquetas de testeo\n",
    "\n",
    "    num_iterations: int\n",
    "                    número de iteraciones para el entrenamiento (por defecto es 2000)\n",
    "\n",
    "    learning_rate: float\n",
    "                   tasa de aprendizaje para el entrenamiento (por defecto es 50%)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    None\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Se inicializan los pesos y el sesgo en 0\n",
    "    W = np.zeros((1, X.shape[1]))\n",
    "    b = 0\n",
    "\n",
    "    # Se obtienen los parámetros optimizados utilizando el conjunto de entrenamiento\n",
    "    W, b = optimizar(W, b, X_train, y_train, num_iterations, learning_rate)\n",
    "\n",
    "    # Se realizan predicciones en el conjunto de testeo y entrenamiento\n",
    "    y_prediction_train = predecir(W, b, X_train)\n",
    "    y_prediction_validation = predecir(W, b, X_val)\n",
    "\n",
    "    # Por último, se calcula el ajuste en ambos conjuntos durante el entrenamiento\n",
    "    accuracy_train = 100 - np.mean(np.abs(y_prediction_train - y_train)) * 100\n",
    "    accuracy_val = 100 - np.mean(np.abs(y_prediction_validation - y_val)) * 100\n",
    "    \n",
    "    return accuracy_train, accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c680b9f-defe-4331-a4a4-3b9285b2a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Datos y transformaciones\n",
    "datos = pd.read_csv('data/Diabetes.txt')\n",
    "X =  np.array(datos.drop([\"Outcome\"], axis = 1))\n",
    "y = np.array(datos[\"Outcome\"])\n",
    "\n",
    "# Normalización de los datos\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "\n",
    "# Separa la muestra\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    \n",
    "    X, # Covaribles predictoras\n",
    "    \n",
    "    y, # Variable a predecir\n",
    "    \n",
    "    random_state = None, # (None: escoge una diferente en cada corrida)\n",
    "    \n",
    "    test_size = 0.20 # Cantidad de datos de entrenamiento y prueba\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f4f64-0fb4-4238-86a5-fcc96100ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un array vacío para guardar los tiempo de ejecución\n",
    "tiempos_ej_9 = np.array([], dtype = float)\n",
    "\n",
    "# Se itera 10 veces para calcular el tiempo de ejecución del proceso cada vez\n",
    "for i in range(10):\n",
    "\n",
    "    inicio = time.time()\n",
    "    \n",
    "    regresion_logistica(\n",
    "        \n",
    "        X_train, y_train, \n",
    "        \n",
    "        X_val, y_val, \n",
    "        \n",
    "        num_iterations = 1000, learning_rate = 0.003\n",
    "        \n",
    "    )\n",
    "\n",
    "    fin = time.time()\n",
    "\n",
    "    # Se guarda el tiempo de ejecución\n",
    "    tiempos_ej_9 = np.append(tiempos_ej_9, (fin - inicio))\n",
    "\n",
    "# Se calcula el promedio del tiempo de ejecución\n",
    "tiempo_promedio_ej_9 = np.sum(tiempos_ej_9) / 10\n",
    "tiempo_promedio_ej_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60dd88-2e3b-48ab-8bd0-ff07d5a40b31",
   "metadata": {},
   "source": [
    "Como se puede observar, el tiempo promedio de ejecución es bastante elevado, ya que la primera iteración demora más tiempo que el resto debido a cómo trabaja Numba. \n",
    "\n",
    "Por lo tanto, se procede a realizar el mismo proceso una segunda vez, en la cual se va a notar que el tiempo promedio de ejecución se redujo significativamente, ya que una vez \"calentadas\" las funciones, Numba hace el proceso mucho más rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356fbf5c-1810-48f5-ba46-702c8731686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempos_ej_9 = np.array([], dtype = float)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    inicio = time.time()\n",
    "    \n",
    "    regresion_logistica(\n",
    "        \n",
    "        X_train, y_train, \n",
    "        \n",
    "        X_val, y_val, \n",
    "        \n",
    "        num_iterations = 1000, learning_rate = 0.003\n",
    "        \n",
    "    )\n",
    "\n",
    "    fin = time.time()\n",
    "    \n",
    "    tiempos_ej_9 = np.append(tiempos_ej_9, (fin - inicio))\n",
    "\n",
    "tiempo_promedio_ej_9 = np.sum(tiempos_ej_9) / 10\n",
    "tiempo_promedio_ej_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea8499-9c0c-4991-8807-f7842c53880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_9 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "    \n",
    "    'tiempo_promedio_inicial': [0, 0.61, 1.01, 0.466],\n",
    "\n",
    "    'tiempo_promedio_posterior': [0, 0.00671, 0.0045, 0.0398]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_9 = pd.DataFrame(data_ej_9)\n",
    "tiempos_ej_9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92e69e-fdd2-40db-a303-fe2e3ce130b4",
   "metadata": {},
   "source": [
    "## Ejercicio 10: Modelo estocástico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794f59b-70de-4616-b2ac-0e197c62414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de datos\n",
    "\n",
    "# Tabla de mortalidad de hombres\n",
    "qx_hombres = pd.read_excel(r'data/Mortalidad_supen.xlsx', sheet_name = 'Sexo_1_limpio')\n",
    "\n",
    "# Tabla de sobrevivencia de hombres\n",
    "px_hombres = 1 - qx_hombres.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f347833-fc80-4d8f-a0ce-767e558cc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que devuelve el índice del primer falso de una fila dada\n",
    "def fila_muerte(fila):\n",
    "\n",
    "    '''\n",
    "    A\n",
    "    '''\n",
    "\n",
    "    fila[np.argmax(fila == False):] = False\n",
    "    \n",
    "    return fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ed0ba-17e5-40b7-bda2-2cef8a1d99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# Función que devuelve las primas del modelo estocástico dada una tabla de sobrevivencia\n",
    "def modelo_estocastico(px):\n",
    "\n",
    "    '''\n",
    "    A\n",
    "    '''\n",
    "\n",
    "    # Tasa equivalente\n",
    "    j = ((1.04) * (1.03)) - 1\n",
    "\n",
    "    # Matriz de ceros\n",
    "    matriz_prob = np.zeros((45, 96))\n",
    "    \n",
    "    # Se rellena la matriz de ceros con las probabilidades de sobrevivencia\n",
    "    for i in range(0, 45):\n",
    "        for k in range(0, 96):\n",
    "            matriz_prob[i, k] = px[min(20 + i + k, 115), 25 + k]\n",
    "\n",
    "    # Se extraen el número de filas y de columnas de la matriz\n",
    "    filmat, colmat = matriz_prob.shape\n",
    "\n",
    "    # Se genera la matriz de números aleatorios basado en la cdf de una N(0, 1)\n",
    "    matriz_rnd = norm.cdf(np.random.normal(loc = 0, scale = 1, size = (filmat, colmat)))\n",
    "\n",
    "    # Se compara la matriz de números aleatorios con la matriz de probabilidades de sobrevivencia\n",
    "    matriz_rnd = matriz_rnd < matriz_prob\n",
    "\n",
    "    # Se agregan falsos después del primer falso a cada fila\n",
    "    matriz_rnd = np.apply_along_axis(fila_muerte, 1, matriz_rnd)\n",
    "\n",
    "    # Se determina el índice del primer falso de cada fila\n",
    "    id = np.sum(matriz_rnd, axis = 1)\n",
    "\n",
    "    # \n",
    "    edades_pensiones = [np.arange(0, max(entrada + 1, 1)) for entrada in (np.minimum(65 - 19 - np.arange(1, 46), id) - 1)]\n",
    "\n",
    "    # Se calcula la anualidad de las primas para cada persona\n",
    "    an = [np.sum(np.power(1/(1+j), np.maximum(edad, 0))) for edad in edades_pensiones]\n",
    "\n",
    "    # Rango de años de cada persona desde que se pensiona hasta su fallecimiento\n",
    "    annos_65 = [np.arange(65 - np.arange(20, 65)[entrada], id[entrada] + 1) for entrada in range(0, 45)]\n",
    "    \n",
    "    # Beneficios para los trabajadores y pensionados\n",
    "    ben = [np.where((id[i] + np.arange(20, 65)[i]) < 65, \n",
    "                    5_000_000 * np.power(1/(1+j), id[i]), \n",
    "                    np.sum(300_000 * 13 * np.power(1/(1+j), annos_65[i])) + 1_000_000 * np.power(1/(1+j), id[i])) for i in range(0, 45)]\n",
    "    \n",
    "    # Se guardan las primeras primas\n",
    "    lista_primas = [np.array(ben)/np.array(an)]\n",
    "\n",
    "    # Se inicializa el promedio de las primas estocásticas\n",
    "    prom_primas = 0\n",
    "\n",
    "    # Se obtienen las primas estocásticas iterando hasta que la diferencia sea menor a 0.001\n",
    "    while(abs(prom_primas - np.mean(np.array(lista_primas))) > 0.001):\n",
    "\n",
    "        # Se crea la matriz de números aleatorios\n",
    "        matriz_rnd = norm.cdf(np.random.normal(loc = 0, scale = 1, size = (filmat, colmat)))\n",
    "\n",
    "        # Se hace la comparación de matrices\n",
    "        matriz_rnd = matriz_rnd < matriz_prob\n",
    "\n",
    "        # Se agregan falsos después del primer falso a cada fila\n",
    "        matriz_rnd = np.apply_along_axis(fila_muerte, 1, matriz_rnd)\n",
    "    \n",
    "        # Se determina el índice del primer falso de cada fila\n",
    "        id = np.sum(matriz_rnd, axis = 1)\n",
    "    \n",
    "        # \n",
    "        edades_pensiones = [np.arange(0, max(entrada + 1, 1)) for entrada in (np.minimum(65 - 19 - np.arange(1, 46), id) - 1)]\n",
    "    \n",
    "        # Se calcula la anualidad de las primas para cada persona\n",
    "        an = [np.sum(np.power(1/(1+j), np.maximum(edad, 0))) for edad in edades_pensiones]\n",
    "    \n",
    "        # Rango de años de cada persona desde que se pensiona hasta su fallecimiento\n",
    "        annos_65 = [np.arange(65 - np.arange(20, 65)[entrada], id[entrada] + 1) for entrada in range(0, 45)]\n",
    "        \n",
    "        # Beneficios para los trabajadores y pensionados\n",
    "        ben = [np.where((id[i] + np.arange(20, 65)[i]) < 65, \n",
    "                        5_000_000 * np.power(1/(1+j), id[i]), \n",
    "                        np.sum(300_000 * 13 * np.power(1/(1+j), annos_65[i])) + 1_000_000 * np.power(1/(1+j), id[i])) for i in range(0, 45)]\n",
    "\n",
    "        # Se actualiza el promedio de las primas\n",
    "        prom_primas = np.mean(np.array(lista_primas))\n",
    "        \n",
    "        # Se agregan las nuevas primas de la iteración a la lista de primas\n",
    "        lista_primas.append(np.array(ben)/np.array(an))\n",
    "    \n",
    "    return lista_primas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ebd42-b2cd-4e1b-b9f2-eb240cd56b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se determina el tiempo (en segundos) que tarda el modelo\n",
    "inicio = time.time()\n",
    "\n",
    "prueba = modelo_estocastico(px_hombres)\n",
    "\n",
    "fin = time.time()\n",
    "\n",
    "tiempo_promedio = (fin - inicio) / len(prueba)\n",
    "tiempo_promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f1fcc-14d4-4af6-94c3-6adf1ec59878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se verifican las iteraciones\n",
    "len(prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a851f-e17d-4f28-b3d5-d425e2d6896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ej_10 = {\n",
    "\n",
    "    'integrante': ['Alejandro', 'Eyeri', 'Santiago', 'Paula'],\n",
    "    \n",
    "    'tiempo': [0, 0.61, 0, 0]\n",
    "    \n",
    "}\n",
    "\n",
    "tiempos_ej_10 = pd.DataFrame(data_ej_10)\n",
    "tiempos_ej_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf3b51-0d72-49d2-a735-f8d6db42ac4f",
   "metadata": {},
   "source": [
    "## Gráficos de tiempos de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cb19a-31c4-4554-8808-f5e51ee189eb",
   "metadata": {},
   "source": [
    "Por último se procede a graficar los tiempos de ejecución de cada integrante en cada uno de los ejercicios.\n",
    "\n",
    "Esto con el objetivo de poder visualizar y comparar los tiempos de ejecución promedio de cada uno de los integrantes en los ejercicios hechos en este lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf94ee8-1b86-443a-b7a8-7c946aa7cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lista_tiempos = [tiempos_ej_1, tiempos_ej_2, tiempos_ej_3, tiempos_ej_4, tiempos_ej_5, tiempos_ej_6]\n",
    "\n",
    "for indice, tiempos_ej in enumerate(lista_tiempos):\n",
    "\n",
    "    if tiempos_ej.shape[1] > 2:\n",
    "\n",
    "        tiempos_ej.set_index('integrante').plot(kind = 'bar', stacked = True, edgecolor = 'black')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        plt.bar(tiempos_ej['integrante'], tiempos_ej['tiempo_promedio'], edgecolor = 'black')\n",
    "\n",
    "    plt.xlabel('Integrante')\n",
    "    \n",
    "    plt.ylabel('Tiempo')\n",
    "    \n",
    "    plt.title(f'Tiempos de ejecución por integrante - Ejercicio {indice + 1}')\n",
    "    \n",
    "    plt.xticks(rotation = 0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931d394-9963-4085-85fa-aa0dab47a11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4da70c-c29d-4dd3-a29c-93ff4e33d2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf2a84-93e0-46b4-b438-17a3e8fb4ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2eb4e-5378-4093-a8f2-dec56e34705d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2f21c-4495-4ac5-a579-2a95c4dbade2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a01616-3433-40ae-8bd9-bccd6fe6e009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
